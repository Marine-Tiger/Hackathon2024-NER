{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr_dep_news_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from extract_corpus import get_coref_corpus\n",
    "\n",
    "corpus = get_coref_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mme        nsubj      NOUN\n",
      "JOUDKIA    flat:name  PROPN\n",
      "est        cop        AUX\n",
      "jolie      ROOT       ADJ\n",
      ".          punct      PUNCT\n",
      "Elle       nsubj      PRON\n",
      "mange      ROOT       VERB\n",
      "des        det        DET\n",
      "fleurs     obj        NOUN\n",
      ".          punct      PUNCT\n",
      "Monsieur   nsubj      NOUN\n",
      "LEBORGNE   flat:name  PROPN\n",
      "est        cop        AUX\n",
      "malade     ROOT       ADJ\n",
      ".          punct      PUNCT\n",
      "Il         nsubj      PRON\n",
      "est        ROOT       VERB\n",
      "à          case       ADP\n",
      "l'         det        DET\n",
      "hopital    obl:arg    NOUN\n",
      ".          punct      PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mme JOUDKIA est jolie. Elle mange des fleurs. Monsieur LEBORGNE est malade. Il est à l'hopital.\")\n",
    "for tok in doc:\n",
    "  print(f\"{tok.text:<10} {tok.dep_:<10} {tok.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "même                 || MM. Désaugiers et Gentil, dont M. Gosse auteur du Médisant, comédie reçue antérieurement à l’Hôtel Garni prétend que le sujet est le même que le M. Gosse auteur du Médisant, comédie reçue antérieurement à l’Hôtel Garni || []\n",
      "=================\n",
      "disponibles          || les 100 F            || []\n",
      "=================\n",
      "disponible           || la gratification     || []\n",
      "=================\n",
      "disponibles          || les 100 F            || []\n",
      "=================\n",
      "inamovibles          || Les deux doyens      || []\n",
      "=================\n",
      "rééligibles          || Les quatre autres membres || []\n",
      "=================\n",
      "nécessaires          || qui                  || []\n",
      "=================\n",
      "agréable             || le témoignage        || []\n",
      "=================\n",
      "relatif              || M. Cartigny          || []\n",
      "=================\n",
      "ancien               || M. Ferriere          || []\n",
      "=================\n",
      "ancien               || M. Ferriere arrêté à M. Baudron, chef, qui atteste que M. Ferriere est le plus ancien des surnuméraires || []\n",
      "=================\n",
      "égal                 || M. Cartigny          || []\n",
      "=================\n",
      "relatif              || qui                  || []\n",
      "=================\n",
      "incompatibles        || les fonctions        || []\n",
      "=================\n",
      "nécessaires          || la présence          || []\n",
      "=================\n",
      "insuffisants         || M. Pécrus moyens     || []\n",
      "=================\n",
      "responsable          || le chef              || []\n",
      "=================\n",
      "quel                 || la durée             || []\n",
      "=================\n",
      "quelles              || les intentions       || []\n",
      "=================\n",
      "telle                || l’incertitude        || []\n",
      "=================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'ents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subj:\n\u001b[1;32m     17\u001b[0m   subj \u001b[38;5;241m=\u001b[39m child\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00madj\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubj\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubj\u001b[38;5;241m.\u001b[39ments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'ents'"
     ]
    }
   ],
   "source": [
    "\n",
    "# for year in corpus:\n",
    "#   print(year)\n",
    "\n",
    "for year in [\"1814\"]:\n",
    "# for year in corpus:\n",
    "  year_text = \"\\n\".join([chunk.text for chunk in corpus[year]]) #le but c'est de concatener le texte de chaque chunk de 1917\n",
    "  doc = nlp(year_text)\n",
    "  adjectifs = [token for token in doc if token.pos_ == \"ADJ\"]\n",
    "  for adj in adjectifs:\n",
    "    for child in adj.children:\n",
    "        if child.dep_ == \"nsubj\":\n",
    "          subj = None\n",
    "          for chunk in doc.noun_chunks:\n",
    "            if (chunk[0].i <= child.i) and (child.i <= chunk[-1].i):\n",
    "              subj = chunk\n",
    "          if not subj:\n",
    "            subj = child\n",
    "          print(f\"{adj.text:<20} || {subj.text:<20} || {subj.}\")\n",
    "          print(\"=================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_text = \"\\n\".join([chunk.text for chunk in corpus['1814']]) #le but c'est de concatener le texte de chaque chunk de 1917\n",
    "doc = nlp(year_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jolie                || Mme JOUDKIA          || []\n",
      "=================\n",
      "malade               || Monsieur LEBORGNE    || []\n",
      "=================\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "doc =  nlp(\"Mme JOUDKIA est jolie. Elle mange des fleurs. Monsieur LEBORGNE est malade. Il est à l'hopital.\")\n",
    "\n",
    "adjectifs = [token for token in doc if token.pos_ == \"ADJ\"]\n",
    "for adj in adjectifs:\n",
    "  for child in adj.children:\n",
    "      if child.dep_ == \"nsubj\":\n",
    "        subj = None\n",
    "        for chunk in doc.noun_chunks:\n",
    "          if (chunk[0].i <= child.i) and (child.i <= chunk[-1].i):\n",
    "            subj = chunk\n",
    "        if not subj:\n",
    "          subj = child\n",
    "        print(f\"{adj.text:<20} || {subj.text:<20} || {subj.ents}\")\n",
    "        print(\"=================\")\n",
    "\n",
    "\n",
    "\n",
    "persons = [ent for ent in doc.ents if ent.label_ == \"PER\"]\n",
    "for person in persons:\n",
    "  if (person.root.head.pos_ == \"ADJ\" and person.root.dep_==\"nsubj\"):\n",
    "    print(f\"{person.text:<20} {person.root.head.text:<20} {person.root.head.pos_:<10} {person.root.dep_}\")\n",
    "print(\"=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "doc = nlp(\"Mme JOUDKIA est jolie. Elle mange des fleurs. Monsieur LEBORGNE est malade et gros. Il est à l'hopital.\")\n",
    "\n",
    "adjectives_subjects = {}\n",
    "def compute_adjectives_subjects(doc):\n",
    "\tlocal_adj_subj = {}\n",
    "\tfor ent in doc.ents:\n",
    "\t\tif ent.label_ == \"PER\":\n",
    "\t\t\tlocal_adj_subj[ent] = []\n",
    "\n",
    "\tfor adjective in local_adj_subj.keys():\n",
    "\t\tfor adj_tok in adjective:\n",
    "\t\t\t\tif (adj_tok.head.pos_ == \"ADJ\"):\n",
    "\t\t\t\t\tlocal_adj_subj[adjective].append(adj_tok.head)\n",
    "    for subject, adjs in local_adj_subj:\n",
    "        print(\"ok\")\n",
    "\t\t\t\t\t\n",
    "\n",
    "compute_adjectives_subjects(doc)\n",
    "compute_adjectives_subjects(doc)\n",
    "for subject, adjs in adjectives_subjects.items():\n",
    "\t\tprint(f\"{subject} -> {adjs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mme                  nsubj:pass           NOUN                \n",
      "JOUDKIA              flat:name            PROPN               \n",
      "est                  cop                  AUX                 \n",
      "jolie                ROOT                 ADJ                 \n",
      ".                    punct                PUNCT               \n",
      "Elle                 nsubj                PRON                \n",
      "mange                ROOT                 VERB                \n",
      "des                  case                 ADP                 \n",
      "fleurs               nmod                 NOUN                \n",
      ".                    punct                PUNCT               \n",
      "Monsieur             nsubj                NOUN                \n",
      "LEBORGNE             nmod                 PROPN               \n",
      "est                  cop                  AUX                 \n",
      "malade               ROOT                 ADJ                 \n",
      "et                   cc                   CCONJ               \n",
      "gros                 conj                 ADJ                 \n",
      ".                    punct                PUNCT               \n",
      "Il                   expl:subj            PRON                \n",
      "est                  cop                  VERB                \n",
      "à                    case                 ADP                 \n",
      "l'                   det                  DET                 \n",
      "hopital              ROOT                 ADJ                 \n",
      ".                    punct                PUNCT               \n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(f\"{tok.text:<20} {tok.dep_:<20} {tok.pos_:<20}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test with stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stanza'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstanza\u001b[39;00m\n\u001b[1;32m      3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m stanza\u001b[38;5;241m.\u001b[39mPipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMme JOUDKIA est jolie. Elle mange des fleurs. Monsieur LEBORGNE est malade. Il est à l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhopital.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stanza'"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(\"fr\")\n",
    "\n",
    "doc = nlp(\"Mme JOUDKIA est jolie. Elle mange des fleurs. Monsieur LEBORGNE est malade. Il est à l'hopital.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recursive_find_adjs(root, sent):\n",
    "    children = [w for w in sent.words if w.head == root.id]\n",
    "\n",
    "    if not children:\n",
    "        return []\n",
    "\n",
    "    filtered_c = [w for w in children if w.deprel == \"conj\" and w.upos == \"ADJ\"]\n",
    "    # Do not include an adjective if it is the parent of a noun to prevent\n",
    "    results = [w for w in filtered_c if not any(sub.head == w.id and sub.upos == \"NOUN\" for sub in sent.words)]\n",
    "    for w in children:\n",
    "        results += recursive_find_adjs(w, sent)\n",
    "\n",
    "    return results\n",
    "\n",
    "for sent in doc.sentences:\n",
    "    nouns = [w for w in sent.words if w.upos == \"NOUN\"]\n",
    "    # print(nouns[0].pretty_print())\n",
    "    # print(\"==\")\n",
    "    noun_adj_pairs = {}\n",
    "    for noun in nouns:\n",
    "        # Find constructions in the form of \"La voiture est belle\"\n",
    "        # In this scenario, the adjective is the parent of the noun\n",
    "        cop_root = sent.words[noun.head-1]\n",
    "        adjs = [cop_root] + recursive_find_adjs(cop_root, sent) if cop_root.upos == \"ADJ\" else []\n",
    "\n",
    "        # Find constructions in the form of \"La femme intelligente et belle\"\n",
    "        # Here, the adjectives are descendants of the noun\n",
    "        mod_adjs = [w for w in sent.words if w.head == noun.id and w.upos == \"ADJ\"]\n",
    "        # This should only be one element because conjunctions are hierarchical\n",
    "        if mod_adjs:\n",
    "            mod_adj = mod_adjs[0]\n",
    "            adjs.extend([mod_adj] + recursive_find_adjs(mod_adj, sent))\n",
    "\n",
    "        if adjs:\n",
    "            unique_adjs = []\n",
    "            unique_ids = set()\n",
    "            for adj in adjs:\n",
    "                if adj.id not in unique_ids:\n",
    "                    unique_adjs.append(adj)\n",
    "                    unique_ids.add(adj.id)\n",
    "\n",
    "            noun_adj_pairs[noun.text] = \" \".join([adj.text for adj in unique_adjs])\n",
    "\n",
    "    print(noun_adj_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon2",
   "language": "python",
   "name": "hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
